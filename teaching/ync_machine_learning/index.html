<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="">
    <!-- <link rel="icon" href="../../favicon.ico"> -->

    <title>YNC Machine Learning</title>

    <!-- Bootstrap core CSS -->
    <link href="../../bootstrap-3.3.6-dist/css/bootstrap.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="../../jumbotron.css" rel="stylesheet">
  </head>

  <body>

    <nav class="navbar navbar-inverse navbar-fixed-top">
    </nav>

    <!-- Main jumbotron for a primary marketing message or call to action -->
    <div class="jumbotron">
      <div class="container"  style="font-size:16px">
        <h2>YSC3227 Machine Learning</h2>
        <p>Semester 2, 2017/2018
	  <br>
          Yale-NUS College
	</p>

      </div>
    </div>


    <div class="container" style="font-size:16px">
      
      
	<center>
      <p class="bg-info">
	<br>
      </p>
	</center>
      <br>

      <h3>Description:</h3>
      <p>
      The goal of machine learning is to enable machines/computers
      to  identify 
      patterns from data, extract the patterns, and based on
      them, make
      an inference 
      or prediction automatically. These capabilities are the core of
      artificial intelligence (namely, to make machines learn
      without being explicitly programmed using fixed predetermined rules). 
      The applications of machine learning are immense, since
      nowadays we are bombarded with a huge number of
      various data from various sources. We hope machine learning can make
      sense of this huge seemingly random  data.
      </p>
      <p>
      This course focuses on the fundamentals of machine learning,
      including and deep learning. It should interest students
      who want to study/work in big data, AI (artificial
      intelligence), and data science.
      </p>
      <br>
      <b>Prerequisite</b>: Programming skill in Python.
      <br>
      <b>Textbook</b>: <a href="http://www.amazon.com/Pattern-Recognition-Learning-Information-Statistics/dp/0387310738/ref=sr_1_1?ie=UTF8&qid=1461689550&sr=8-1&keywords=pattern+recognition+and+machine+learning"
      target="_blank">"Pattern Recognition and Machine Learning"</a>,
      by Christopher Bishop. 

      <br>
      <b>Instructor</b>: <a href="http://tanrobby.github.io">Robby
      T. Tan</a> (robby.tan [att] yale-nus.edu.sg)
      <br>
      <br>
      <hr>
      <h3 id="schedule">Schedule:</h3>
<p>
The following schedule will not be strictly followed.
</p>

<br>
      
<table width="100%" 
       border = "0"
       class="table table-striped">
  <thead class="thead-inverse">
    
    <tr>
      <th width="12%"> Date
      <th> <center> Topic </center>
      <th width="20%"> <center> Lecture Note </center>
  </thead>
  <tbody>
    
    
    <!------------------------------------------------------------------------------>	  
    
    
    <tr>
      <td rowspan="1"> August 15
      <td>
	
	<b>1. LEAST SQUARES</b>
	<br>
	<br>
	Reading:
	<ul>
	  <li> Chapter 1: Introduction (Sect. 1.1)
	</ul>
	<br>
	Additional reading (optional):
	<ul>
	  <li> Introduction to Machine Learning:
	  <a href="http://www.cs.princeton.edu/courses/archive/spr08/cos511/scribe_notes/0204.pdf"
	  target="_blank">pdf</a> | <a href="https://www.youtube.com/watch?v=cKxRvEZd3Mw" target="_blank">youtube</a>
	</ul>
	<br>
      <td align="left">
	Lecture note 1
	<br>
	<a href="assignment1.html" target="_blank">Assignment 1</a>
    </tr>
    
     <!------------------------------------------------------------------------------>
    
    
    <tr>
      <td rowspan="1"> August 8
      <td>
	<b> 2. INTRO TO BAYESIAN INFERENCE</b>
	<br>
	<br>
    </tr>
	    
    <!------------------------------------------------------------------------------>
    
    <tr>
      <td rowspan="1"> August 22
      <td>
	<b>3. MLE AND MAP FOR REGRESSION</b>
	<br>
	<br>
	
      <td align="left">
    </tr>
    
    <!------------------------------------------------------------------------------>
    
    <tr>
      <td rowspan="1"> August 25
      <td>
	<b>4. BASIS FUNCTIONS</b>
	<br>
	<br>
      <td align="left">
    </tr>

    <!------------------------------------------------------------------------------>
    
	
    <tr>
      <td rowspan="1"> August 29
      <td>
	<b>5. GAUSSIAN DISTRIBUTIONS: COVARIANCE MATRIX</b>
	<br>
	<br>
      <td align="left">
    </tr>

    
    <!------------------------------------------------------------------------------>
    
    <tr>
      <td rowspan="1"> September 5
      <td>
	<b>6. CONDITIONAL AND MARGINAL GAUSSIAN DISTRIBUTIONS</b>
	<br>
	<br>
      <td align="left">
    </tr>
    
    <!------------------------------------------------------------------------------>
    
    
    <tr>
      <td rowspan="1"> September 8
      <td>
	<b>7. BAYES' THEOREM FOR GAUSSIAN VARIABLES</b>
	<br>
	<br>
      <td align="left">
    </tr>
    
    <!------------------------------------------------------------------------------>
    
    
    <tr>
      <td rowspan="1"> September 12
      <td>
	<b>8. SEQUENTIAL BAYESIAN LEARNING</b>
	<br>
	<br>
	
      <td align="left">
    </tr>

    <!------------------------------------------------------------------------------>
	
   <tr>
     <td rowspan="1"> September 15
     <td> 
       <b>9. REVIEW: METHODS FOR ESTIMATING W</b>
       <br>
       <br>
     <td align="left">
    </tr>
    <!------------------------------------------------------------------------------>
    
    
    <tr>
      <td rowspan="1"> September 19
      <td>
	<b>10. PREDICTIVE DISTRIBUTION</b>
	<br>
	<br>
      <td align="left">
    </tr>
    <!------------------------------------------------------------------------------>

    
    <tr>
      <td rowspan="1">  September 22
      <td>
	<b>11. GAUSSIAN PROCESSES 1</b>
	<br>
	<br>
      <td align="left">
    </tr>

    
    <!------------------------------------------------------------------------------>

    <tr class="success">
      
      <td rowspan="1"> 
      <td>
	<b> RECESS WEEK </b>
	<br>
	<br>		
      <td>
    </tr>
    
    <!------------------------------------------------------------------------------>

    <tr>
      
      <td rowspan="1"> October 3
      <td>
	<b>12. GAUSSIAN PROCESSES 2</b>
	<br>
	<br>
      <td align="left">
    </tr>


    <!------------------------------------------------------------------------------>


	
    <tr>
      <td rowspan="1"> October 6
      <td>
 	<b>13. CLASSIFICATION: LEAST SQUARES</b>
	<br>
	<br>
      <td align="left">
    </tr>

    <!------------------------------------------------------------------------------>

	
    <tr>
      <td rowspan="1"> October 10
      <td>
	<b>14. FISHER'S LINEAR DISCRIMINANT ANALYSIS</b>
	<br>
	<br>
      <td align="left">
    </tr>

    <!------------------------------------------------------------------------------>

    
    <tr>
      <td rowspan="1"> October 13
      <td>
	<b>15. DETAILS OF FISHER'S LDA</b>
	<br>
	<br>
	
      <td align="left">
    </tr>
    
    <!------------------------------------------------------------------------------>

    
	
    <tr>
      <td rowspan="1"> October 17
      <td>
	<b>16. PROBABILISTIC GENERATIVE + DISCRIMINATIVE MODELS</b>
	<br>
	<br>
      <td align="left">
    </tr>

    <!------------------------------------------------------------------------------>
    
    
    
    <tr>
      <td rowspan="1"> October 20
      <td>
	<b>17. BAYESIAN LOGISTIC REGRESSION</b>
	<br>
	<br>
      <td align="left">
    </tr>

    <!------------------------------------------------------------------------------>

    
    
    <tr>
      <td rowspan="1"> October 24
      <td>
	<b>18. GAUSSIAN PROCESSES FOR CLASSIFICATION</b>
	<br>
	<br>
      <td align="left">
    </tr>
    
    <!------------------------------------------------------------------------------>
    
    
    
    <tr>
      <td rowspan="1"> October 27
      <td>
	<b>19. GAUSSIAN PROCESSES FOR CLASSIFICATION: 2</b>
	<br>
	<br>
      <td align="left">
    </tr>

    <!------------------------------------------------------------------------------>

	
    <tr>
	<td rowspan="1"> October 31
	<td>
	  <b>20. NEURAL NETWORKS</b>
	  <br>
	  <br>
	<td align="left">
    </tr>

    <!------------------------------------------------------------------------------>
	  
    
    <tr>
      <td rowspan="1"> November 3
      <td>
	  <b>21. NEURAL NETWORKS: BACKPROPAGATION</b>
	  <br>
	  <br>
      <td align="left">
    </tr>
    
    <!------------------------------------------------------------------------------>
    
    
    <tr>
      <td rowspan="1"> November 7
      <td>
	  <b>22. DEEP LEARNING: FURTHER ISSUES</b>
	  <br>
	  <br>
      <td align="left">
    </tr>
    
    <!------------------------------------------------------------------------------>

	
    <tr>
      <td rowspan="1"> November 10
      <td>
	<b>23. DEEP LEARNING: ARCHITECTURES</b>
	<br>
	<br>
      <td align="left">
    </tr>
    
    <!------------------------------------------------------------------------------>

    <tr>
      <td rowspan="1"> November 14
      <td>
	<b>24. MIXTURE MODELS + EM ALGORITHM</b>
	<br>
	<br>
      <td align="left">
    </tr>
    
    <!------------------------------------------------------------------------------>

    <tr>
      <td rowspan="1"> November 17
      <td>
	<b>25. DISCUSSION</b>
	<br>
	<br>
      <td align="left">
    </tr>
    
    <!------------------------------------------------------------------------------>
    

    <tr class="danger">
      <td rowspan="1"> December 1
      <td>
	<b>FINAL EXAM: 1pm to 4pm (Classroom 20) <b>
	<br>
	<br>

	<td align="left"> 
    </tr>


    
  </tbody>
</table>
<br>


<!------------------------------------------------------------------------------>
<!------------------------------------------------------------------------------>
<!------------------------------------------------------------------------------>
<!------------------------------------------------------------------------------>

<br>
<br>

      <hr>
      <h3 id="syllabus">Syllabus:</h3>
      <br>
      <ul>
	<li> Least Squares for Regression
	<li> Bayes' Theorem, MAP, MLE and Full Bayesian Inference
	<li> Gaussian Distributions
	<li> Bayesian Sequential Learning
	<li> Predictive Distribution
	<li> Gaussian Processes for Regression
	<li> Least Squares for Classification
	<li> Fisher's Linear Discriminative Analysis
	<li> Probabilistic Generative and Discriminative Models
	<li> Bayesian Logistic Regression
	<li> Gaussian Processes for Classification
	<li> Neural Networks
	<li> Deep Learning
      </ul>

<br>
<hr>
<br>
<br>
<br>

      

</div>      
    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script>window.jQuery || document.write('<script src="../../assets/js/vendor/jquery.min.js"><\/script>')</script>
    <script src="bootstrap-3.3.6-dist/js/bootstrap.min.js"></script>
  </body>
  <script type="text/javascript">
    var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
    document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
  </script>
<script type="text/javascript">
  try {
  var pageTracker = _gat._getTracker("UA-13131132-3");
  pageTracker._trackPageview();
  } catch(err) {}</script>
</html>
