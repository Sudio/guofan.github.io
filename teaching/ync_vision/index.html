<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="">
    <!-- <link rel="icon" href="../../favicon.ico"> -->
    
    <title>YNC Computer Vision</title>
    
    <!-- Bootstrap core CSS -->
    <link href="../../bootstrap-3.3.6-dist/css/bootstrap.css" rel="stylesheet">
    
    <!-- Custom styles for this template -->
    <link href="../../jumbotron.css" rel="stylesheet">
  </head>
  
  <body>
    
    <nav class="navbar navbar-inverse navbar-fixed-top">
    </nav>
    
    <!-- Main jumbotron for a primary marketing message or call to action -->
    <div class="jumbotron">
      <div class="container"  style="font-size:16px">
        <h2>YSC3221 Computer Vision</h2>
        <p>Semester 1, 2017/2018
	  <br>
          Yale-NUS College
	</p>
      </div>
    </div>
    
    
    <div class="container" style="font-size:16px">
      
      
      <p class="bg-info">
	<br>
	<br>
	<br>
      </p>
      <br>

      <h3>Description:</h3>
      <p>
	Images and videos are everywhere. Using your mobile phone, it
	becomes easy to snap a picture or to record video. Yet, how
	can we automatically extract the rich visual information from
	those images and videos? This is the task computer vision
	attempts to solve, namely, to understand or extract any
	information from images or videos.
	The goal of computer vision is to make computers work like human
	visual perception, namely, to understand and recognize the world
	through visual information, such as, images or videos. Human visual
	perception, after millions of years of evolution, is extremely good in
	understanding and recognizing objects or scenes. To have similar
	abilities to human visual perception (or beyond), computer scientists
	have been developing algorithms by relying on various visual
	information, and this course is about some of these algorithms. 
	
	In case you are wondering why we should care about computer vision,
	consider this: if you think your eyes are important
	and beneficial, so is computer vision. 
      </p>
      <br>
      <b>Prerequisite</b>: Programming skill in either python, c/c++,
      or matlab.
      <br>
      <b>Textbook:</b> <a href="http://www.amazon.com/Computer-Vision-Models-Learning-Inference/dp/1107011795/ref=sr_1_1?ie=UTF8&qid=1461727721&sr=8-1&keywords=Computer+Vision%3A+Models%2C+Learning%2C+and+Inference"
      target="_blank">Computer Vision: Models, Learning, and 
      Inference</a>, by S.J.D. Prince. The ebook version is accessible
      through NUS library. Note, we will use the book loosely (some,
      if not many, topics are taken from other sources).
      <br>
      
      <b>Instructor</b>: <a href="http://tanrobby.github.io">Robby
      T. Tan</a> (robby.tan [att] yale-nus.edu.sg)
      <br>
      <br>
      <br>
            
<hr>
<h3>Teaching Schedule:</h3>
<p>
The following schedule will not be strictly followed.
</p>

<br>
      
<table width="100%" 
       border = "0"
       class="table table-striped">
  <thead class="thead-inverse">
    
    <tr>
      <th width="12%"> Date
      <th> <center> Topic </center>
      <th width="25%"> <center> Lecture Note </center>
  </thead>
  <tbody>
    
    
    <!------------------------------------------------------------------------------>	  
    
    
    <tr>
      <td rowspan="1"> August 12
      <td>
	
	<b>1. INTRODUCTION</b>
	<br>
	<br>
	Additional resources:
	<ul>
	  <li> Brief introduction to computer vision:
	  <a href="https://www.youtube.com/watch?v=wthBcVFouzY&index=4&list=PLAwxTw4SYaPnbDacyrK_kB_RUkuxQBlCm"
	  target="_blank">youtube</a>
	</ul>
	<br>
      <td align="left">
	<a href="https://www.dropbox.com/s/hzw2ahn0g70fmnj/lecture01.pdf?dl=0" target="_blank">Slide 1</a>
    </tr>
    
    <!------------------------------------------------------------------------------>
    
    
    <tr>
      <td rowspan="1"> August 16
      <td>
	<b> 2. FACE DETECTION (VIOLA-JONES)</b>
	<br>
	<br>

	Reading:
	<ul>
	  <li> Viola-Jones' algorithm:
	    <a href="http://www.vision.caltech.edu/html-files/EE148-2005-Spring/pprs/viola04ijcv.pdf"
	       target="_blank">pdf</a> | <a href="https://www.youtube.com/watch?v=sWTvK72-SPU" target="_blank">youtube</a>
	    
	</ul>
	<br>
	Additional resources:
	<ul>
	  <li>AdaBoost:
	    <a href="http://cseweb.ucsd.edu/~yfreund/adaboost/index.html"
	       target="_blank">demo applet</a> |
	    <a href="http://www.robots.ox.ac.uk/~az/lectures/cv/adaboost_matas.pdf"
	       target="_blank">slides</a> | 
  	    <a href="http://videolectures.net/mlss05us_schapire_b"
  	       target="_blank">online lecture</a> 
	  <li> Haar-like Features: <a href="http://en.wikipedia.org/wiki/Haar-like_features"
				      target="_blank">wikipedia</a>
	  <li> Integral Images: <a href="http://en.wikipedia.org/wiki/Summed_area_table"
				   target="_blank">wikipedia</a>
	</ul>
	<br>
	
      <td>
	<a href="https://www.dropbox.com/s/7xb78s4cdivz2yb/lecture02.pdf?dl=0"
	   target="_blank">Note 2</a>
	<br>
	<a href="https://www.dropbox.com/s/kln1g59lfi8057n/slides02.pdf?dl=0"
	   target="_blank">Slide 2</a>
	<br>
	<a href="homework01.html" target="_blank">Homework 1</a> 
	
      <td>
    </tr>
	    
    <!------------------------------------------------------------------------------>
    
    <tr>
      <td rowspan="1"> August 19
      <td>
	<b>3. FEATURES + DESCRIPTORS</b>
	<br>
	<br>
	Reading:
	<ul>
	  <li> Textbook Chapter 13: Image Preprocessing and Feature
	    Extraction, particularly Sec. 13.1 (per-pixel
	    transformations), and Sec. 13.3.3 (Histogram of Oriented
	    Gradients)
	  <li> HoG for Human
	    Detection: <a href="https://lear.inrialpes.fr/people/triggs/pubs/Dalal-cvpr05.pdf" 
			  target="_blank">pdf</a>
	    
	    | <a href="https://www.youtube.com/watch?v=7S5qXET179I" target="_blank">youtube 1</a>
	    | 
	    <a href="https://www.youtube.com/watch?v=0Zib1YEE4LU"
	       target="_blank">youtube 2</a> 
	</ul>
	<br>
	
      <td align="left">
	<a href="https://www.dropbox.com/s/9381ovr18vgtp09/lecture03.pdf?dl=0" target="_blank">Note 3</a>
    </tr>
    
    <!------------------------------------------------------------------------------>
    
    <tr>
      <td rowspan="1"> August 23
      <td>
	<b>4. SIFT </b>
	<br>
	<br>
	Reading:
	<ul>
          <li>Textbook: Chapter 13, Sec. 13.2 (edges, corners, and
          interest points), Sec. 13.3 (descriptors)
	  <li> SIFT
	    [<a href="http://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf"
		target="_blank">PDF</a>]
	  <li> Matrix calculus: <a href="https://en.wikipedia.org/wiki/Matrix_calculus" target="_blank">wikipedia</a>
	</ul>
	<br>
	Additional resources:
	<ul>
	  <li> Features: SIFT
	    <a  href="http://www.cs.ubc.ca/~lowe/keypoints/siftDemoV4.zip"
		 target="_blank">executable program</a> 
	    | <a  href="http://www.cs.ubc.ca/~lowe/keypoints" target="_blank">website</a>
	  <li> Object search: 
	    <a href="http://www.robots.ox.ac.uk/~vgg/research/oxbuildings/index.html"
		target="_blank">demo</a>
	  <li> Video google:
	    <a href="http://www.robots.ox.ac.uk/~vgg/research/vgoogle/index.html"
		target="_blank">demo</a>
	</ul> 
	<br>
	
      <td align="left">
	<a href="https://www.dropbox.com/s/az7p8jqi693dqd3/slide04.pdf?dl=0"
	   target="_blank">Slide 4</a>
	<br>
	<a href="https://www.dropbox.com/s/ubiwgh9k3webqzy/lecture04.pdf?dl=0"
	target="_blank">Note 4</a>
    </tr>

    <!------------------------------------------------------------------------------>
    
	
    <tr>
      <td rowspan="1"> August 28
      <td>
	<b>5. SIFT II</b>
	<br>
	<br>
	
      <td align="left">
	<a href="homework02.html" target="_blank">Homework 2</a> 
    </tr>

    
    <!------------------------------------------------------------------------------>
    
    <tr>
      <td rowspan="1"> August 30
      <td>
	<b>6. BAGS OF VISUAL WORDS</b>
	<br>
	<br>
	Reading:
	<ul>
	  <li>K-means: <a href="https://en.wikipedia.org/wiki/K-means_clustering" target="_blank">wikipedia</a>
          <li>Textbook: 
	    Chapter 20.1 (images as collections of visual words) and
	    20.2 (bag of words).
	</ul>
	<br>
	
      <td align="left">
	<a href="https://www.dropbox.com/s/8bar8blqifxbd4q/slide05.pdf?dl=0"
	   target="_blank">Slide 5</a>
	<br>
    </tr>
    
    <!------------------------------------------------------------------------------>
    
    
    <tr>
      <td rowspan="1"> September 2
      <td>
	<b>7. NEURAL NETWORKS: INTRODUCTION</b> 
	<br>
	<br>
	Additional resources:
	<ul>
	  <li> Introduction to neural network
	  <a href="https://www.youtube.com/watch?v=P2HPcj8lRJE"
	  target="_blank">youtube</a>
	  <li> An introduction to neural networks:
	    <a href="http://lia.univ-avignon.fr/chercheurs/torres/livres/book-neuro-intro.pdf"
	    target="_blank">PDF</a>
	  <li> A brief introduction to neural networks:
	    <a href="http://www.dkriesel.com/_media/science/neuronalenetze-en-zeta2-2col-dkrieselcom.pdf"
	    target="_blank">PDF</a>
	</ul>
	<br>
      <td align="left">
	<a href="homework03.html" target="_blank">Homework 3</a>
    </tr>
    
    <!------------------------------------------------------------------------------>
    
    
    <tr>
      <td rowspan="1"> September 6
      <td>
	<b>8. NEURAL NETWORKS: INTRODUCTION II</b> 
	<br>
	<br>
	Reading:
	<ul>
	  <li> Michael Nielsen's Online Book, Chapter 1:
	    <a href="http://neuralnetworksanddeeplearning.com/chap1.html" target="_blank">website</a>
	</ul>
	<br>
      <td align="left">
	<a href="https://www.dropbox.com/s/v7jttckyrpxzddv/lecture08.pdf?dl=0" target="_blank">Note 8</a>
	<br>
    </tr>

    <!------------------------------------------------------------------------------>
	
   <tr>
     <td rowspan="1"> September 9
     <td> 
       <b>9. DEEP LEARNING: INTRODUCTION</b>
       <br>
       <br>
	Reading:
	<ul>
	  <li> Michael Nielsen's Online Book, Chapter 2:
	    <a href="http://neuralnetworksanddeeplearning.com/chap2.html" target="_blank">website</a>
	</ul>
	<br>
    
    <td align="left">
      <a href="https://www.dropbox.com/s/4mbgkrzr0qtd29w/lecture09.pdf?dl=0" target="_blank">Note 9</a>
    </tr>
    <!------------------------------------------------------------------------------>
    
    
    <tr>
      <td rowspan="1"> September 13
      <td>
	<b>10. DEEP LEARNING: FORMULATION I</b>
       <br>
       <br>
	Reading:
	<ul>
	  <li> Michael Nielsen's Online Book, Chapter 3 (Cross Entropy):
	    <a href="http://neuralnetworksanddeeplearning.com/chap3.html" target="_blank">website</a>
	</ul>
	<br>
      <td align="left">
	<a href="https://www.dropbox.com/s/287s5i473ij1dow/lecture10.pdf?dl=0"
	target="_blank">Note 10</a>
    </tr>
    <!------------------------------------------------------------------------------>

    
    <tr>
      <td rowspan="1"> September 16
      <td>
	<b>11. DEEP LEARNING: FORMULATION 2</b>
	<br>
	<br>
	Reading:
	<ul>
	  <li> Michael Nielsen's Online Book, Chapter 3 (Softmax, Overfitting
	  and Regularization):
	    <a href="http://neuralnetworksanddeeplearning.com/chap3.html" target="_blank">website</a>
	</ul>
	<br>

      <td align="left">
	 <a href="homework04.html" target="_blank">Homework 4</a> 

    </tr>

    <!------------------------------------------------------------------------------>

    <tr class="success">
      
      <td rowspan="1">
      <td>
	<b> RECESS WEEK </b>
	<br>
	<br>		
      <td>
    </tr>

    <!------------------------------------------------------------------------------>

	
    <tr>
      <td rowspan="1"> September 27
      <td>
	<b>12. CONVOLUTIONAL NEURAL NETWORKS</b>
	<br>
	<br>
	Reading:
	<ul>
	  <li> Michael Nielsen's Online Book, Chapter 6:
	    <a href="http://neuralnetworksanddeeplearning.com/chap6.html"
	       target="_blank">website</a>
	  <li> For more detailed information on CNNs and its
	  visualization, watch the following online lectures from
	  Lecture 7 to  12 (you can skip Lecture 10). Lecture video 9
	  discusses the visualization of CNNs: <a href="https://www.youtube.com/watch?v=LxfUGhug-iQ&index=7&list=PLkt2uSq6rBVctENoVBg1TpCC7OQi31AlC" target="_blank">youtube</a>.
	</ul>
	<br>

      <td align="left">


    </tr>

    <!------------------------------------------------------------------------------>

	
    <tr>
      <td rowspan="1"> September 30
      <td>
	<b>13. CAMERA GEOMETRIC PROPERTIES and CALIBRATION</b>
	<br>
	<br>
	Reading:
	<ul>
	  <li> Textbook chapter 14 (Pinhole Camera): sect. 14.1 (the
	  pinhole camera), 14.3
	  (homogeneous coordinates),
	  14.4 (learning extrinsic parameters), and 14.5 (learning intrinsic parameters)
	</ul>
      <td align="left">
	<a href="https://www.dropbox.com/s/80b8a5pkrz9smrg/lecture13.pdf?dl=0" target="_blank">Note 13</a>
    </tr>

    <!------------------------------------------------------------------------------>

	
    <tr>
      <td rowspan="1"> October 4
      <td>
	<b>14. TWO VIEW GEOMETRY</b>
	<br>
	<br>
	Reading:
	<ul>
	  <li> Textbook chapter 16 (Multiple Cameras): sect. 16.1
	  (two-view geometry), sect. 16.2 (essential matrix),
	  sect. 16.3 (fundamental matrix), sect. 16.4 (two-view
	    reconstruction pipeline).
	</ul>

	<td align="left">
	  <a href="https://www.dropbox.com/s/ugmanxdi1g6b2tj/lecture14.pdf?dl=0" target="_blank">Note 14</a>
    </tr>

    <!------------------------------------------------------------------------------>

    
    <tr>
      <td rowspan="1"> October 7
      <td>
	<b>15.  TWO VIEW GEOMETRY II</b>
	<br>
	<br>
	Additional reading (optional):
	<ul>
	  <li> Multiple View Geometry (by Richard Hartley and Andrew
	    Zisserman), online version is available through the NUS library: Chapter 9 (sect. 9.1 and sect. 9.2), and Chapter
	    10 (sect. 10.1, 10.2 and 10.3).
	  <li> Hartley's tutorial on multiple view
	  geometry: <a href="http://users.cecs.anu.edu.au/~hartley/Papers/CVPR99-tutorial/tutorial.pdf"
		       target="_blank">PDF</a>
	</ul>
      <td align="left">
	  <a href="homework05.html" target="_blank"> Homework 5</a>
	  <br>
    </tr>
    
    <!------------------------------------------------------------------------------>
    
    
    <tr>
      <td rowspan="1"> October 11
      <td>
	<b>16. DEPTH FROM STEREO + MARKOV RANDOM FIELDS</b>
	<br>
	<br>
	Reading:
	<ul>
	  <li> Textbook: Chapter 12 (Models for grids): sect. 12.1
	  (Markov random fields).
	</ul>
	<br>
	Additional reading (optional):
	<ul>
	  <li> Textbook: Chapter 1 (Introduction to probability)
	  <li> Textbook: Chapter 10 (Graphical model): sect. 10.1 to 10.3.
	</ul>
	<br>
      <td align="left">
	<a href="https://www.dropbox.com/s/8x71b7pgn3hp466/lecture16.pdf?dl=0" target="_blank">Note 16</a>
    </tr>
    
    <!------------------------------------------------------------------------------>

    
    <tr>
      <td rowspan="1"> October 14
      <td>
	<b>17. GRAPHCUTS + DEPTH ESTIMATION</b>
	<br>
	<br>
	Additional reading (optional):
	<ul>
	  <li> Textbook: Chapter 12 (Models for grids): sect. 12.2
	    (MAP inference for binary pairwise MRFs).
	  <li> Depth Map from a Video Sequence, TPAMI'09: 
	    [<a href="http://www.cad.zju.edu.cn/home/bao/pub/Consistent_Depth_Maps_Recovery_from_a_Video_Sequence.pdf"
		target="_blank">pdf</a>]
	  <li> Comments on Depth Map from a Video Sequence, UU-TR'11:
	    [<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.437.4926&rep=rep1&type=pdf"
		target="_blank">pdf</a>]
	</ul>
	<br>
      <td align="left">
	<a href="https://www.dropbox.com/s/duktrp2zuj8nzkj/lecture17.pdf?dl=0"
	   target="_blank">Note 17</a>
	<br>
	<a href="homework06/index.html" target="_blank">Homework 6</a>

    </tr>

    <!------------------------------------------------------------------------------>


	
    <tr>
      <td rowspan="1"> October 18
      <td>
	<b>18. DIRECTED GRAPHS: CHAINS AND TREES</b>
	<br>
	<br>
	Reading:
	<ul>
	  <li> Textbook: Chapter 11 (Models for chains and trees):
	    sect. 11.1 to sect. 11.3.
	</ul>
	<br>
      <td align="left">
	<a href="https://www.dropbox.com/s/qx804iiy3al9mda/lecture18.pdf?dl=0" target="_blank">Note 18</a>

    </tr>

    <!------------------------------------------------------------------------------>
    
    
    
    <tr>
      <td rowspan="1"> October 21
      <td> 
	<b>19. HUMAN POSE ESTIMATION USING A TREE (PICTORIAL STRUCTURE)</b>
	<br>
	<br>
	Reading:
	<ul>
	  <li> Pictorial Structure Revisited: <a href="http://web.mpi-inf.mpg.de/fileadmin/inf/d2/andriluka/andriluka_cvpr09.pdf" target="_blank">pdf</a>
	</ul>
	<br>
      <td align="left">
	<a href="https://www.dropbox.com/s/izty9czksnhlabc/slide18.pdf?dl=0"
	target="_blank">Slide 19</a>

    </tr>

    <!------------------------------------------------------------------------------>

    
    
    <tr>
      <td rowspan="1"> October 25
      <td>
	<b>20. HUMAN POSE ESTIMATION 2</b>
	<br>
	<br>
	<br>
      <td align="left">

    </tr>
    
    <!------------------------------------------------------------------------------>
    
    
    
    <tr>
      <td rowspan="1"> October 28
      <td>
	<b> 21. OPTICAL FLOW</b>
	<br>
	<br>
	Reading:
	<ul>
	  <li> Lucas-Kanade optical flow: <a href="http://ijcai.org/Past%20Proceedings/IJCAI-81-VOL-2/PDF/017.pdf" target="_blank">pdf</a>
	  <li> Horn-Schunck optical flow: <a href="http://image.diku.dk/imagecanon/material/HornSchunckOptical_Flow.pdf" target="_blank">pdf</a>
	 </ul>
      <td align="left">
	<a href="https://www.dropbox.com/s/kwuuvrzig6eii19/lecture21.pdf?dl=0" target="_blank">Note 21</a>

	
    </tr>

    <!------------------------------------------------------------------------------>

	
    <tr>
	<td rowspan="1"> November 1
	<td>
	  <b>22. OPTICAL FLOW 2</b>
	<br>
	<br>
	<td align="left">


    </tr>

    <!------------------------------------------------------------------------------>
	  
    
    <tr>
      <td rowspan="1"> November 4
      <td>
	<b>23. PHOTOMETRIC STEREO</b>
	<br>
	<br>
	Reading:
	<ul>
	  <li> Youtube
	  demos: <a href="https://www.youtube.com/watch?v=2JrwRT9_vO4"
	  target="_blank">demo1</a>
	  | <a href="https://www.youtube.com/watch?v=2JrwRT9_vO4"
	  target="_blank">demo2</a> 
	  <li> Photometric stereo: <a href="http://www.macs.hw.ac.uk/texturelab/files/publications/phds_mscs/JW/chapter4.pdf" target="_blank">pdf</a>.
	</ul>
      <td align="left">
    </tr>
    
    <!------------------------------------------------------------------------------>
    
    
    <tr>
      <td rowspan="1"> November 8
      <td>
	<b>24. PHYSICS-BASED VISION</b>
	<br>
	<br>

      <td align="left"> 

    </tr>
    
    <!------------------------------------------------------------------------------>

	
    <tr>
      <td rowspan="1"> November 11
      <td>
	<b>25. REVIEW + QA SESSION</b>
	<br>
	<br>
      <td align="left"> 
	<a href="https://www.dropbox.com/s/ygc4yoesphvcg3y/samples.pdf?dl=0" target="_blank">Sample Questions</a>
    </tr>
    
    <!------------------------------------------------------------------------------>
	

    <tr class="danger">
      <td rowspan="1"> November 25
      <td>
	<b>FINAL EXAM (14.30 - 17.30)<b>
	<br>
	<br>
	
	<td align="left"> 
	  Classroom 19
    </tr>


    
  </tbody>
</table>
<br>


<!------------------------------------------------------------------------------>
<!------------------------------------------------------------------------------>
<!------------------------------------------------------------------------------>
<!------------------------------------------------------------------------------>

<br>
<br>
<br>
<hr>
<br>
<br>
<br>


</div>      
    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script>window.jQuery || document.write('<script src="../../assets/js/vendor/jquery.min.js"><\/script>')</script>
    <script src="bootstrap-3.3.6-dist/js/bootstrap.min.js"></script>
  </body>
  <script type="text/javascript">
    var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
    document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
  </script>
<script type="text/javascript">
  try {
  var pageTracker = _gat._getTracker("UA-13131132-3");
  pageTracker._trackPageview();
  } catch(err) {}</script>
</html>
