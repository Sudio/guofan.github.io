<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="">
    <!-- <link rel="icon" href="../../favicon.ico"> -->
    
    <title>YNC Computer Vision and Deep Learning</title>
    
    <!-- Bootstrap core CSS -->
    <link href="../../bootstrap-3.3.6-dist/css/bootstrap.css" rel="stylesheet">
    
    <!-- Custom styles for this template -->
    <link href="../../jumbotron.css" rel="stylesheet">
  </head>
  
  <body>
    
    <nav class="navbar navbar-inverse navbar-fixed-top">
    </nav>
    
    <!-- Main jumbotron for a primary marketing message or call to action -->
    <div class="jumbotron">
      <div class="container"  style="font-size:16px">
        <h2>YSC3221 Computer Vision and Deep Learning</h2>
        <p>Semester 2, 2017/2018
	  <br>
          Yale-NUS College
	</p>
      </div>
    </div>
    
    
    <div class="container" style="font-size:16px">
      
      
      <p class="bg-info">
	<br>
	<br>
	<br>
      </p>
      <br>

      <h3>Description:</h3>
      <p>
	Images and videos are everywhere. Using your mobile phone, it
	becomes easy to snap a picture or to record video. Yet, how
	can we automatically extract the rich visual information from
	those images/videos? This is the task computer vision
	attempts to solve.
	The goal of computer vision is to make computers work like human
	visual perception, namely, to understand and recognize the world
	through visual data. One important technique in computer
	vision is deep learning. Deep learning is able to extract
	features and to infer the visual information from the features
	automatically and accurately. This course will focus on the
	fundamentals of deep learning and its applications to computer vision.

      </p>
      <br>
      <b>Prerequisite</b>: Programming skill in python, and maths
      (linear algebra, calculus, statistics/probability).
      <br>
      <b>Textbook:</b>
      <ol>
	<li><a href="http://www.amazon.com/Computer-Vision-Models-Learning-Inference/dp/1107011795/ref=sr_1_1?ie=UTF8&qid=1461727721&sr=8-1&keywords=Computer+Vision%3A+Models%2C+Learning%2C+and+Inference"
	       target="_blank">Computer Vision: Models, Learning, and 
	    Inference</a>, by S.J.D. Prince.
	<li> <a href="http://www.deeplearningbook.org/"
	target="_blank">Deep Learning</a>, by Ian Goodfellow and Yoshua Bengio and Aaron Courville
      </ol>
      The ebook versions are accessible
      through NUS library. Note, we will use the books loosely (some,
      if not many, topics are taken from other sources).
      <br>
      
      <b>Instructor</b>: <a href="http://tanrobby.github.io">Robby
      T. Tan</a> (robby.tan [att] yale-nus.edu.sg)
      <br>



<hr>
<h3>Lecture Schedule:</h3>
<p>
The following schedule will not be strictly followed.
</p>
<br>

<table width="100%" 
       class="table table-striped">
  <thead class="thead-inverse">
    
    <tr>
      <th width="12%"> Date
      <th> <center> Topic </center>
      <th width="25%"> <center> Lecture Note </center>
  </thead>
  <tbody>
    
    <!------------------------------------------------------------------------------>
    
    <tr>
      <td rowspan="1"> January 15
      <td>
	<b>1. INTRODUCTION</b> 
	<br>
	<br>
	Additional resources:
	<ul>
	  <li> Brief introduction to computer vision:
	  <a href="https://www.youtube.com/watch?v=wthBcVFouzY&index=4&list=PLAwxTw4SYaPnbDacyrK_kB_RUkuxQBlCm"
	  target="_blank">youtube</a>
	</ul>
	<br>
      <td align="left"> 
	<a href="https://www.dropbox.com/s/anyt1nocsxtenot/YSC3221_slide1.pdf?dl=0" target="_blank">Lecture 1</a>
    </tr>

    
    <!------------------------------------------------------------------------------>

    <tr>
      <td rowspan="1"> January 18
      <td> 
	<b>2. FACE DETECTION: FEATURES + BOOSTING</b>
	<br>
	<br>
	Reading:
	<ul>
	  <li> Viola-Jones' algorithm:
	    <a href="http://www.vision.caltech.edu/html-files/EE148-2005-Spring/pprs/viola04ijcv.pdf"
	       target="_blank">pdf</a> | <a href="https://www.youtube.com/watch?v=sWTvK72-SPU" target="_blank">youtube</a>
	    
	</ul>
	<br>
	Additional resources:
	<ul>
	  <li>AdaBoost:
	    <a href="http://cseweb.ucsd.edu/~yfreund/adaboost/index.html"
	       target="_blank">demo applet</a> |
	    <a href="http://www.robots.ox.ac.uk/~az/lectures/cv/adaboost_matas.pdf"
	       target="_blank">slides</a> | 
  	    <a href="http://videolectures.net/mlss05us_schapire_b"
  	       target="_blank">online lecture</a> 
	  <li> Haar-like Features: <a href="http://en.wikipedia.org/wiki/Haar-like_features"
				      target="_blank">wikipedia</a>
	  <li> Integral Images: <a href="http://en.wikipedia.org/wiki/Summed_area_table"
				   target="_blank">wikipedia</a>
	</ul>
	<br>
	
	<td align="left">
	  <a href="https://www.dropbox.com/s/ja7ozhvz4jqwqaw/YSC3221_lecture02.pdf?dl=0"
	  target="_blank">Lecture 2</a>
    </tr>
    
    
    <!------------------------------------------------------------------------------>
    
    <tr>
      <td rowspan="1"> January 22
	<td> 
	  <b>3. FACE DETECTION: ADABOOST CLASSIFICATION</b>
	  <br>
	  <br>
	<td align="left">
    </tr>
    
    
    <!------------------------------------------------------------------------------>
    
    <tr>
      <td rowspan="1"> January 25
      <td> 
	  Class Cancelled
	  <br>
	  <br>
      <td align="left">
    </tr>
    
    
    <!------------------------------------------------------------------------------>
    
    <tr>
      <td rowspan="1"> January 29
      <td> 
	Class Cancelled
	<br>
	<br>
      <td align="left">
    </tr>

    
    <!------------------------------------------------------------------------------>
    
    <tr>
      <td rowspan="1"> February 1
      <td>
	<b>4. FACE DETECTION: INTEGRAL IMAGE + CASCADE </b>
	<br>
	<br>
	
      <td align="left">
    </tr>
    
    <!------------------------------------------------------------------------------>
    
    <tr>
      <td rowspan="1"> February 5
      <td>
        <b>5. FEATURES AND DESCRIPTORS: HoG + SIFT</b>
	<br>
	<br>
	Reading:
	<ul>
	  <li> Textbook Chapter 13: Image Preprocessing and Feature
	    Extraction, particularly Sec. 13.1 (per-pixel
	    transformations), and Sec. 13.3.3 (Histogram of Oriented
	    Gradients)
	  <li> HoG for Human
	    Detection: <a href="https://lear.inrialpes.fr/people/triggs/pubs/Dalal-cvpr05.pdf" 
			  target="_blank">pdf</a>
	    
	    | <a href="https://www.youtube.com/watch?v=7S5qXET179I" target="_blank">youtube 1</a>
	    | 
	    <a href="https://www.youtube.com/watch?v=0Zib1YEE4LU"
	       target="_blank">youtube 2</a> 
	</ul>
	<br>
      <td align="left">
	<a href="https://www.dropbox.com/s/1quik0wfs3eejbg/YSC3221_lecture05.pdf?dl=0"
	target="_blank">Lecture 5</a> 
	<br>
	<a href="assignment1/index.html" target="_blank">Assignment 1</a>
    </tr>
    
    
    <!------------------------------------------------------------------------------>
    
    <tr>
      <td rowspan="1"> February 8
      <td>
	<b>6. SIFT (Part 1)</b>
	<br>
	<br>
	Reading:
	<ul>
          <li>Textbook: Chapter 13, Sec. 13.2 (edges, corners, and
          interest points), Sec. 13.3 (descriptors)
	  <li> SIFT
	    [<a href="http://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf"
		target="_blank">PDF</a>]
	  <li> Matrix calculus: <a href="https://en.wikipedia.org/wiki/Matrix_calculus" target="_blank">wikipedia</a>
	</ul>
	<br>
	Additional resources:
	<ul>
	  <li> Features: SIFT
	    <a  href="http://www.cs.ubc.ca/~lowe/keypoints/siftDemoV4.zip"
		 target="_blank">executable program</a> 
	    | <a  href="http://www.cs.ubc.ca/~lowe/keypoints" target="_blank">website</a>
	  <li> Object search: 
	    <a href="http://www.robots.ox.ac.uk/~vgg/research/oxbuildings/index.html"
		target="_blank">demo</a>
	  <li> Video google:
	    <a href="http://www.robots.ox.ac.uk/~vgg/research/vgoogle/index.html"
	       target="_blank">demo</a>
	</ul> 
	<br>
      <td align="left">
	<a href="https://www.dropbox.com/s/ayz2opxuo2hdedq/YSC3221_slide6.pdf?dl=0" target="_blank">Slide 6</a>
	<br>
	<a href="https://www.dropbox.com/s/vgbsqtfmgjy04dw/YSC3221_lecture06.pdf?dl=0"
	target="_blank">Lecture 6</a> 
    </tr>
    

    <!------------------------------------------------------------------------------>

    <tr>
      <td rowspan="1"> February 12
      <td>
	<b>7. SIFT (Part 2)</b>
	<br>
	<br>
      <td align="left">
    </tr>
    
    <!------------------------------------------------------------------------------>
    
    <tr>
      <td rowspan="1"> February 15
      <td>
	<b>8. IMAGE STITCHING</b>
	<br>
	<br>
	Reading:
	<ul>
	  <li> Homography: <a href="https://en.wikipedia.org/wiki/Homography" target="_blank">wikipedia</a>
	  <li> RANSAC: <a href="https://en.wikipedia.org/wiki/Random_sample_consensus" target="_blank">wikipedia</a>
	</ul>
	<br>
	Additional resources:
	<ul>
	  <li> Automatic Panoramic Image Stitching Using Invariant
	  Features:
	  <a href="http://matthewalunbrown.com/papers/ijcv2007.pdf"
	  target="_blank">pdf</a> 
	  <li> Image Alignment and Stitching: A Tutorial:
	  <a href="http://www.cs.toronto.edu/~kyros/courses/2530/papers/Lecture-14/Szeliski2006.pdf"
	  target="_blank">pdf</a>
	</ul>
      <td align="left">
	<a href="https://www.dropbox.com/s/7mpekqs5zkqvrvi/YSC3221_lecture08.pdf?dl=0" target="_blank">Lecture 8</a>
    </tr>
    
    
    <!------------------------------------------------------------------------------>
    
    <tr>
      <td rowspan="1"> February 19
      <td>
	<b>9. CAMERA GEOMETRY</b>
	<br>
	<br>
	Reading: 
	<ul>
	  <li> Textbook chapter 14 (Pinhole Camera): sect. 14.1 (the
	  pinhole camera), 14.3
	  (homogeneous coordinates),
	</ul>
      <td align="left">
	<a href="https://www.dropbox.com/s/yzxtjqtylc5piov/YSC3221_lecture09.pdf?dl=0"
	target="_blank">Lecture 9</a>
    </tr>
    <!------------------------------------------------------------------------------>


        <tr>
      <td rowspan="1"> February 22
      <td>
	<b>10. CAMERA CALIBRATION</b>
	<br>
	<br>
	Reading: 
	<ul>
	  <li> Textbook chapter 14 (Pinhole Camera): sect. 14.2 (three 
	  geometric problems), sect. 14.4 (learning extrinsic
	  parameters), sect. 14.5 (learning intrinsic parameters)
	</ul>
      <td align="left">
	<a href="https://www.dropbox.com/s/s3qv8lf91xwodbf/YSC3221_lecture10.pdf?dl=0">Lecture 10</a>
	</tr>
	
    
    
    <!------------------------------------------------------------------------------>
    <!------------------------------   RECESS WEEK  -------------------------------->
    <!------------------------------------------------------------------------------>
    
    <tr class="success">
      
      <td rowspan="1">
      <td>
	<br>	
	<b> RECESS WEEK </b>
	<br>
	<br>		
      <td>
    </tr>
    
    <!------------------------------------------------------------------------------>
    
    
    
    
    <tr>
      <td rowspan="1"> March 5
      <td>
	<b>11. CAMERA CALIBRATION 2</b>
	<br>
	<br>
      <td align="left">
    </tr>
    
    
    
    <!------------------------------------------------------------------------------>
    
    <tr>
      <td rowspan="1"> March 8
      <td>
	<b>12. GRAPHICAL MODELS</b>
	<br>
	<br>
	Additional reading (optional):
	<ul>
	  <li> Textbook: Chapter 1 (Introduction to probability)
	  <li> Textbook: Chapter 10 (Graphical model): sect. 10.1 to 10.3.
	</ul>
	
      <td align="left">
    </tr>

    
    
    
    <!------------------------------------------------------------------------------>
    
    <tr>
      <td rowspan="1"> March 12
      <td>
	<b>13. MARKOV RANDOM FIELD</b>
	<br>
	<br>
      <td align="left">
    </tr>
    
    
    <!------------------------------------------------------------------------------>
    
    <tr>
      <td rowspan="1"> March 15
      <td>
	<b>14. CONVOLUTIONAL NEURAL NETWORKS</b>
	<br>
	<br>
      <td align="left">
    </tr>
    
    
    <!------------------------------------------------------------------------------>
    
    <tr>
      <td rowspan="1"> March 19
      <td>
	<b>15. DEEP GENERATIVE NETWORKS: AUTOENCODERS</b>
	<br>
	<br>
      <td align="left">
    </tr>
    
    
    <!------------------------------------------------------------------------------>
    
    <tr>
      <td rowspan="1"> March 22
      <td>
	<b>18. GENERATIVE ADVERSARIAL NETWORKS </b>
	<br>
	<br>
      <td align="left"> 
    </tr>
    
    
    
    <!------------------------------------------------------------------------------>
    
    <tr>
      <td rowspan="1"> March 26
      <td>
	<b> 19. RECURRENT NEURAL NETWORKS</b>
	<br>
	<br>
      <td align="left">
    </tr>

    
    <!------------------------------------------------------------------------------>
    
    <tr>
      <td rowspan="1"> March 29
      <td>
	<b>20. DEEP BELIEF NETWORKS</b>
	<br>
	<br>
      <td align="left">
    </tr>
    
    

    <!------------------------------------------------------------------------------>
    
    <tr>
      <td rowspan="1"> April 2
      <td>
	<b>21. IMAGE EDITING: IMAGE INPAINTING</b>
	<br> 
	<br>
      <td align="left">
    </tr>
    
    
    
    <!------------------------------------------------------------------------------>
    
    
    
    <tr>
      <td rowspan="1"> April 5
      <td>
	
	<b>22. IMAGE EDITING: GRADIENT SPACE MANIPULATION</b>
	<br>
	<br>
      <td align="left">
    </tr>
    
    
    <!------------------------------------------------------------------------------>

    <tr>
      <td rowspan="1"> April 9
      <td> 
	<b>23. OPTICAL FLOW 1</b>	
	<br>
	<br>	
      <td align="left">
    </tr>
    
    
    <!------------------------------------------------------------------------------>

    <tr>
      <td rowspan="1"> April 12
      <td>
	<b>24. OPTICAL FLOW 2</b>
	<br>
	<br>
      <td align="left"> 
    </tr>
    
    
    
    <!------------------------------------------------------------------------------>
    
    <tr>
      <td rowspan="1"> April 16
      <td>
	<b>25. LOW LEVEL VISION</b>
	<br>
	<br>
      <td align="left"> 
    </tr>
    
    <!------------------------------------------------------------------------------>
    

    <tr class="danger">
      <td rowspan="1"> April 19
      <td>
	<b>25. REVIEW + QA SESSION</b>
	<br>
	<br>
	
      <td align="left"> 
    </tr>

    
    <!------------------------------------------------------------------------------>
    

    
  </tbody>
</table>
<br>
<br>
<br>


<!--------------------------------------------------------------->
<!--------------------------------------------------------------->
<!--------------------------------------------------------------->
<!--------------------------------------------------------------->

      

      
      <hr>
      <br>
<h3>Syllabus:</h3>
<ul>
<li>Introduction
<li>Image Features
<li>Matching and Recognition
<li>Neural Networks: Basics
<li>Neural Networks: Training
<li>Deep Learning: Convolutional Neural Networks
<li>Deep Learning: Autoencoders
<li>Deep Learning: Recurrent Neural Networks
<li>Camera geometric properties
<li>Multiview geometry
<li>Markov Random Fields
<li>Depth from Stereo
<li>Motion Analysis
<li>Low-level Vision
<li>Image Editing
</ul>


<br>
<hr>
<br>



</div>      
    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script>window.jQuery || document.write('<script src="../../assets/js/vendor/jquery.min.js"><\/script>')</script>
    <script src="bootstrap-3.3.6-dist/js/bootstrap.min.js"></script>
  </body>
  <script type="text/javascript">
    var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
    document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
  </script>
<script type="text/javascript">
  try {
  var pageTracker = _gat._getTracker("UA-13131132-3");
  pageTracker._trackPageview();
  } catch(err) {}</script>
</html>
